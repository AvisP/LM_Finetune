{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nHF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")\nHF_TOKEN_WRITE = user_secrets.get_secret(\"HF_TOKEN_WRITE\")\nHF_TOKEN_WRITE = user_secrets.get_secret(\"HF_TOKEN_WRITE\")","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:38:36.304256Z","iopub.execute_input":"2024-04-26T19:38:36.304552Z","iopub.status.idle":"2024-04-26T19:38:36.735562Z","shell.execute_reply.started":"2024-04-26T19:38:36.304526Z","shell.execute_reply":"2024-04-26T19:38:36.734534Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install huggingface_hub\n\n# from huggingface_hub import notebook_login\n# notebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:38:36.736934Z","iopub.execute_input":"2024-04-26T19:38:36.737224Z","iopub.status.idle":"2024-04-26T19:38:50.081141Z","shell.execute_reply.started":"2024-04-26T19:38:36.737198Z","shell.execute_reply":"2024-04-26T19:38:50.080103Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.22.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"!huggingface-cli login --token $HF_TOKEN","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:38:50.082592Z","iopub.execute_input":"2024-04-26T19:38:50.082899Z","iopub.status.idle":"2024-04-26T19:38:51.714547Z","shell.execute_reply.started":"2024-04-26T19:38:50.082870Z","shell.execute_reply":"2024-04-26T19:38:51.713522Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"!huggingface-cli login --token $HF_TOKEN_WRITE","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:38:51.717593Z","iopub.execute_input":"2024-04-26T19:38:51.717935Z","iopub.status.idle":"2024-04-26T19:38:53.315077Z","shell.execute_reply.started":"2024-04-26T19:38:51.717905Z","shell.execute_reply":"2024-04-26T19:38:53.313733Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -U transformers[torch] datasets","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:38:53.316809Z","iopub.execute_input":"2024-04-26T19:38:53.317146Z","iopub.status.idle":"2024-04-26T19:39:08.230078Z","shell.execute_reply.started":"2024-04-26T19:38:53.317114Z","shell.execute_reply":"2024-04-26T19:39:08.228749Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.0)\nRequirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.40.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.29.3)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q bitsandbytes trl peft accelerate","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:39:08.232363Z","iopub.execute_input":"2024-04-26T19:39:08.232833Z","iopub.status.idle":"2024-04-26T19:39:23.060065Z","shell.execute_reply.started":"2024-04-26T19:39:08.232790Z","shell.execute_reply":"2024-04-26T19:39:23.058686Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"!pip install flash-attn --no-build-isolation","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:39:23.061719Z","iopub.execute_input":"2024-04-26T19:39:23.062067Z","iopub.status.idle":"2024-04-26T19:39:36.860841Z","shell.execute_reply.started":"2024-04-26T19:39:23.062035Z","shell.execute_reply":"2024-04-26T19:39:36.859609Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Requirement already satisfied: flash-attn in /opt/conda/lib/python3.10/site-packages (2.5.7)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash-attn) (2.1.2)\nRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from flash-attn) (0.7.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from flash-attn) (21.3)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash-attn) (1.11.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->flash-attn) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash-attn) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\n\n# based on config\nraw_datasets = load_dataset(\"HuggingFaceH4/ultrachat_200k\")","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:39:36.862495Z","iopub.execute_input":"2024-04-26T19:39:36.862863Z","iopub.status.idle":"2024-04-26T19:39:43.970377Z","shell.execute_reply.started":"2024-04-26T19:39:36.862831Z","shell.execute_reply":"2024-04-26T19:39:43.969179Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from datasets import DatasetDict\n\n# remove this when done debugging to include whole dataset\nindices = range(0,500)\n\ndataset_dict = {\"train\": raw_datasets[\"train_sft\"].select(indices),\n                \"test\": raw_datasets[\"test_sft\"].select(indices)}\n\nraw_datasets = DatasetDict(dataset_dict)\nraw_datasets","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:39:43.972087Z","iopub.execute_input":"2024-04-26T19:39:43.972554Z","iopub.status.idle":"2024-04-26T19:39:43.990093Z","shell.execute_reply.started":"2024-04-26T19:39:43.972526Z","shell.execute_reply":"2024-04-26T19:39:43.989016Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'prompt_id', 'messages'],\n        num_rows: 500\n    })\n    test: Dataset({\n        features: ['prompt', 'prompt_id', 'messages'],\n        num_rows: 500\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets[\"train\"][:2]['messages']","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:39:43.991551Z","iopub.execute_input":"2024-04-26T19:39:43.992182Z","iopub.status.idle":"2024-04-26T19:39:44.001597Z","shell.execute_reply.started":"2024-04-26T19:39:43.992144Z","shell.execute_reply":"2024-04-26T19:39:44.000649Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[[{'content': \"These instructions apply to section-based themes (Responsive 6.0+, Retina 4.0+, Parallax 3.0+ Turbo 2.0+, Mobilia 5.0+). What theme version am I using?\\nOn your Collections pages & Featured Collections sections, you can easily show the secondary image of a product on hover by enabling one of the theme's built-in settings!\\nYour Collection pages & Featured Collections sections will now display the secondary product image just by hovering over that product image thumbnail.\\nDoes this feature apply to all sections of the theme or just specific ones as listed in the text material?\",\n   'role': 'user'},\n  {'content': 'This feature only applies to Collection pages and Featured Collections sections of the section-based themes listed in the text material.',\n   'role': 'assistant'},\n  {'content': 'Can you guide me through the process of enabling the secondary image hover feature on my Collection pages and Featured Collections sections?',\n   'role': 'user'},\n  {'content': \"Sure, here are the steps to enable the secondary image hover feature on your Collection pages and Featured Collections sections:\\n\\n1. Log in to your Shopify account and go to your Online Store.\\n2. Click on Customize theme for the section-based theme you are using.\\n3. Navigate to the Collection pages or Featured Collections section where you want to enable the secondary image hover feature.\\n4. With the section open, click on the section's setting (gear) icon in the top-left corner.\\n5. In the settings panel that appears, look for an option labeled 'Image display' or 'Image hover'.\\n6. If available, select 'Show secondary image on hover'.\\n7. Save the changes and preview the Collection/Featured Collection page to see the effect.\\n\\nIf you're having trouble finding the setting, the best thing to do is refer to your theme's documentation, since the location and labeling of settings can vary between themes.\",\n   'role': 'assistant'},\n  {'content': 'Can you provide me with a link to the documentation for my theme?',\n   'role': 'user'},\n  {'content': \"I don't have access to your store's theme information. However, you can usually find the documentation for your theme by going to the shopify theme store, finding your theme and clicking on the 'support' link located in the bottom right corner of the page. Alternatively, you can do a google search for the name of your theme followed by 'documentation' or 'user guide'.\",\n   'role': 'assistant'},\n  {'content': 'Can you confirm if this feature also works for the Quick Shop section of my theme?',\n   'role': 'user'},\n  {'content': \"The secondary image hover feature may or may not work for your Quick Shop section, depending on the configuration of your theme. Some themes include this feature in the Quick Shop section by default, while others may require additional customization. To check if this feature is available for the Quick Shop section of your theme, follow these steps:\\n\\n1. Go to the Quick Shop section where you would like to enable the feature. 2. Click on the Quick Shop settings icon (gear icon) and look for 'Image display' or 'Image hover'. 3. If available, select 'Show secondary image on hover'. 4. Save the changes. If this option is not available in your Quick Shop section settings, you may need to reach out to your theme developer for assistance with customizing your Quick Shop section to include this feature.\",\n   'role': 'assistant'}],\n [{'content': 'Which famous landmarks should I visit in London, beyond the usual ones?',\n   'role': 'user'},\n  {'content': \"1. Leadenhall Market - a beautiful indoor market with stunning Victorian architecture, also used as a filming location in the Harry Potter films.\\n\\n2. St. Dunstan in the East - a ruined church in the middle of the city that has been turned into a beautiful public garden.\\n\\n3. The Monument - a 202-foot-tall column commemorating the Great Fire of London, with a staircase leading to a viewing platform offering great views of the city.\\n\\n4. The Camden Town Markets - an eclectic collection of markets offering food, fashion, and vintage items, plus live music and street performers.\\n\\n5. Novelist's House - the former home of Charles Dickens, now a museum dedicated to his life and works.\\n\\n6. The Old Operating Theatre - a museum housed in the oldest surviving operating theatre in Europe, with exhibits on the history of surgery and medical practices.\\n\\n7. The Churchill War Rooms - an underground complex used as a British government command centre during World War II, now a museum dedicated to Winston Churchill and his leadership during the war.\\n\\n8. The Brunel Museum - a museum dedicated to the life and works of engineer Isambard Kingdom Brunel, with exhibitions on his revolutionary designs for bridges, ships, and tunnels.\\n\\n9. The Clink Prison Museum - a museum in the former site of the notorious medieval prison, with exhibits on the history of crime and punishment in London.\\n\\n10. The Royal Observatory Greenwich - an observatory and museum dedicated to astronomy and navigation, with exhibits on the history of timekeeping and space exploration.\",\n   'role': 'assistant'},\n  {'content': \"Hmm, those are interesting suggestions, but I've already seen so many touristy landmarks in London. Is there something more offbeat that you can recommend? Something that locals might know about?\",\n   'role': 'user'},\n  {'content': \"Absolutely! Here are some offbeat and lesser-known things to see in London that locals might recommend:\\n\\n1. God's Own Junkyard - a neon wonderland filled with vintage and new neon signs.\\n\\n2. Hornsey Town Hall Arts Centre - a grade II listed building with a rich history and home to many art exhibitions and events.\\n\\n3. Clapham Grand - a historic Victorian theatre that has been transformed into a music venue, cinema and a comedy club.\\n\\n4. Gordon Museum of Pathology - the pathology museum of King's College in London that holds a collection of over 8,000 medical specimens.\\n\\n5. John Soane's Museum - the former home of wealthy architect John Soane is a museum with eclectic collections of paintings, sculptures, and curiosities.\\n\\n6. The Viktor Wynd Museum of Curiosities - a small museum filled with strange and unusual objects, taxidermy, and rare books.\\n\\n7. The Cross Bones Graveyard - a medieval graveyard that became known as an outcast cemetery with a history connected to the sex industry, now a memorial garden.\\n\\n8. Highgate Cemetery - a beautiful Victorian graveyard known for its Gothic architecture and where many famous people, including Karl Marx, are buried.\\n\\n9. Dalston Eastern Curve Garden - a beautiful community garden near the Dalston Junction station that is run by volunteers and has regular events.\\n\\n10. The Geffrye Museum of the Home - a museum that explores the history of domestic interiors in England, with a beautiful garden and regular market events.\\n\\nThere are many other hidden gems in London, and a quick Google search for ‘offbeat things in London’ will bring up many blogs and resources with more options.\",\n   'role': 'assistant'},\n  {'content': \"Wow, these offbeat suggestions are really interesting. I had no idea there were so many unique things to see in London. Thanks for the recommendations, you're much more helpful than I expected. Can you tell me more about the Viktor Wynd Museum of Curiosities? It sounds like my kind of place.\",\n   'role': 'user'},\n  {'content': \"Sure! The Viktor Wynd Museum of Curiosities, Fine Art & Natural History is a small museum located in Hackney, East London. The museum, founded by collector Viktor Wynd is a place where you can find taxidermy, books, anatomical models, and other curiosities. The museum is famous for its collection of shrunken heads, dodo bones, and the famous mermaid. It is also notable for its dimly lit, atmospheric decor, and its bar which serves cocktails and allows visitors to take drinks into the museum. The museum is open daily except for Mondays and Tuesdays, and it also frequently hosts events and exhibitions, so be sure to check the museum's website to see what's on.\",\n   'role': 'assistant'},\n  {'content': \"Woah, the Viktor Wynd Museum sounds like a wacky and fun place to visit. I don't think I've ever seen a shrunken head before. I wonder what kind of cocktails they serve there... Maybe I can convince some friends to check it out with me!\",\n   'role': 'user'},\n  {'content': 'Yes, the museum is definitely one of the more unusual places to visit in London! The cocktail menu at Viktor Wynd\\'s bar is just as eclectic as the museum\\'s collection, featuring brightly colored cocktails inspired by the exhibits, such as the \"Shrunken Head\" or \"Mermaid Tail\" cocktails. The museum and bar are on the smaller side, so it would make for a unique and intimate outing with friends. If you\\'re looking for something different and memorable to do in London, the Viktor Wynd Museum is definitely worth checking out!',\n   'role': 'assistant'},\n  {'content': \"Whoa, a bar in a museum?! That's wild. I'm definitely going to have to try one of those cocktails. Do you think they have anything with a shrunken head as a garnish? That would be a trip.\",\n   'role': 'user'},\n  {'content': \"I am not sure if the Viktor Wynd Museum of Curiosities serves cocktails with an actual shrunken head as a garnish. However, they might have some creative cocktails that incorporate a shrunken head replica or something similar as an element in the drink. Nevertheless, the bar offers a unique setting and a cocktail menu that includes some unusual ingredients so it's definitely worth checking out! It's likely to be an eccentric and memorable experience, and I'm sure you'll have a great time there with your friends.\",\n   'role': 'assistant'},\n  {'content': 'I can\\'t wait to see that mermaid at the Viktor Wynd Museum. I wonder if it\\'s real or just a replica. Either way, it\\'s bound to be a fascinating item to behold. And I\\'ll make sure to order that \"Mermaid Tail\" cocktail while I\\'m there!',\n   'role': 'user'},\n  {'content': 'Yes, the mermaid at the Viktor Wynd Museum of Curiosities is definitely one of its most famous exhibits. It\\'s actually a recreation made from the skeleton of a monkey and the tail of a fish, so it\\'s not a real mermaid of course, but it\\'s still an intriguing piece. The museum has many other curiosities to discover as well, and the atmosphere there is unlike anything you\\'ll find in other museums. And don\\'t forget to try that \"Mermaid Tail\" cocktail - it\\'s the perfect accompaniment to the museum\\'s quirky vibe!',\n   'role': 'assistant'}]]"},"metadata":{}}]},{"cell_type":"code","source":"example = raw_datasets[\"train\"][0]\nmessages = example[\"messages\"]\nfor message in messages:\n  role = message[\"role\"]\n  content = message[\"content\"]\n  print('{0:20}:  {1}'.format(role, content))","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:39:44.003084Z","iopub.execute_input":"2024-04-26T19:39:44.003697Z","iopub.status.idle":"2024-04-26T19:39:44.014926Z","shell.execute_reply.started":"2024-04-26T19:39:44.003648Z","shell.execute_reply":"2024-04-26T19:39:44.013986Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"user                :  These instructions apply to section-based themes (Responsive 6.0+, Retina 4.0+, Parallax 3.0+ Turbo 2.0+, Mobilia 5.0+). What theme version am I using?\nOn your Collections pages & Featured Collections sections, you can easily show the secondary image of a product on hover by enabling one of the theme's built-in settings!\nYour Collection pages & Featured Collections sections will now display the secondary product image just by hovering over that product image thumbnail.\nDoes this feature apply to all sections of the theme or just specific ones as listed in the text material?\nassistant           :  This feature only applies to Collection pages and Featured Collections sections of the section-based themes listed in the text material.\nuser                :  Can you guide me through the process of enabling the secondary image hover feature on my Collection pages and Featured Collections sections?\nassistant           :  Sure, here are the steps to enable the secondary image hover feature on your Collection pages and Featured Collections sections:\n\n1. Log in to your Shopify account and go to your Online Store.\n2. Click on Customize theme for the section-based theme you are using.\n3. Navigate to the Collection pages or Featured Collections section where you want to enable the secondary image hover feature.\n4. With the section open, click on the section's setting (gear) icon in the top-left corner.\n5. In the settings panel that appears, look for an option labeled 'Image display' or 'Image hover'.\n6. If available, select 'Show secondary image on hover'.\n7. Save the changes and preview the Collection/Featured Collection page to see the effect.\n\nIf you're having trouble finding the setting, the best thing to do is refer to your theme's documentation, since the location and labeling of settings can vary between themes.\nuser                :  Can you provide me with a link to the documentation for my theme?\nassistant           :  I don't have access to your store's theme information. However, you can usually find the documentation for your theme by going to the shopify theme store, finding your theme and clicking on the 'support' link located in the bottom right corner of the page. Alternatively, you can do a google search for the name of your theme followed by 'documentation' or 'user guide'.\nuser                :  Can you confirm if this feature also works for the Quick Shop section of my theme?\nassistant           :  The secondary image hover feature may or may not work for your Quick Shop section, depending on the configuration of your theme. Some themes include this feature in the Quick Shop section by default, while others may require additional customization. To check if this feature is available for the Quick Shop section of your theme, follow these steps:\n\n1. Go to the Quick Shop section where you would like to enable the feature. 2. Click on the Quick Shop settings icon (gear icon) and look for 'Image display' or 'Image hover'. 3. If available, select 'Show secondary image on hover'. 4. Save the changes. If this option is not available in your Quick Shop section settings, you may need to reach out to your theme developer for assistance with customizing your Quick Shop section to include this feature.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# model_id = \"mistralai/Mistral-7B-v0.2\"\nmodel_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:39:44.016000Z","iopub.execute_input":"2024-04-26T19:39:44.016274Z","iopub.status.idle":"2024-04-26T19:39:51.520211Z","shell.execute_reply.started":"2024-04-26T19:39:44.016250Z","shell.execute_reply":"2024-04-26T19:39:51.519225Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:39:51.524692Z","iopub.execute_input":"2024-04-26T19:39:51.525149Z","iopub.status.idle":"2024-04-26T19:39:51.531598Z","shell.execute_reply.started":"2024-04-26T19:39:51.525122Z","shell.execute_reply":"2024-04-26T19:39:51.530490Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"128001"},"metadata":{}}]},{"cell_type":"code","source":"terminators = [\n    tokenizer.eos_token_id,\n    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n]","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:39:51.533060Z","iopub.execute_input":"2024-04-26T19:39:51.533427Z","iopub.status.idle":"2024-04-26T19:39:51.545584Z","shell.execute_reply.started":"2024-04-26T19:39:51.533394Z","shell.execute_reply":"2024-04-26T19:39:51.544729Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import re\nimport random\nfrom multiprocessing import cpu_count\n\ndef apply_chat_template(example, tokenizer):\n    messages = example[\"messages\"]\n    # We add an empty system message if there is none\n    if messages[0][\"role\"] != \"system\":\n        messages.insert(0, {\"role\": \"system\", \"content\": \"\"})\n    example[\"text\"] = tokenizer.apply_chat_template(messages, tokenize=False)\n\n    return example","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:39:51.546858Z","iopub.execute_input":"2024-04-26T19:39:51.547139Z","iopub.status.idle":"2024-04-26T19:39:51.560581Z","shell.execute_reply.started":"2024-04-26T19:39:51.547115Z","shell.execute_reply":"2024-04-26T19:39:51.559623Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"column_names = list(raw_datasets[\"train\"].features)\nraw_datasets = raw_datasets.map(apply_chat_template,\n                                num_proc=cpu_count(),\n                                fn_kwargs={\"tokenizer\": tokenizer},\n                                remove_columns=column_names,\n                                desc=\"Applying chat template\",)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:39:51.561630Z","iopub.execute_input":"2024-04-26T19:39:51.561915Z","iopub.status.idle":"2024-04-26T19:39:52.038504Z","shell.execute_reply.started":"2024-04-26T19:39:51.561892Z","shell.execute_reply":"2024-04-26T19:39:52.037514Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"raw_datasets","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:39:52.039901Z","iopub.execute_input":"2024-04-26T19:39:52.040288Z","iopub.status.idle":"2024-04-26T19:39:52.047059Z","shell.execute_reply.started":"2024-04-26T19:39:52.040238Z","shell.execute_reply":"2024-04-26T19:39:52.046122Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text'],\n        num_rows: 500\n    })\n    test: Dataset({\n        features: ['text'],\n        num_rows: 500\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# set pad_token_id equal to the eos_token_id if not set\nif tokenizer.pad_token_id is None:\n  tokenizer.pad_token_id = tokenizer.eos_token_id\n\n# Set reasonable default for models without max length\nif tokenizer.model_max_length > 100_000:\n  tokenizer.model_max_length = 2048","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:39:52.048406Z","iopub.execute_input":"2024-04-26T19:39:52.048922Z","iopub.status.idle":"2024-04-26T19:39:52.060281Z","shell.execute_reply.started":"2024-04-26T19:39:52.048889Z","shell.execute_reply":"2024-04-26T19:39:52.059308Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# create the splits\ntrain_dataset = raw_datasets[\"train\"]\neval_dataset = raw_datasets[\"test\"]\n\nfor index in random.sample(range(len(raw_datasets[\"train\"])), 3):\n  print(f\"Sample {index} of the processed training set:\\n\\n{raw_datasets['train'][index]['text']}\")\n  print(\"#####################################\")","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:39:52.061389Z","iopub.execute_input":"2024-04-26T19:39:52.061692Z","iopub.status.idle":"2024-04-26T19:39:52.076472Z","shell.execute_reply.started":"2024-04-26T19:39:52.061642Z","shell.execute_reply":"2024-04-26T19:39:52.075359Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Sample 490 of the processed training set:\n\n<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease write a Python program that will read and write data to a JSON file using the appropriate built-in functions. The JSON file should contain a list of dictionaries, where each dictionary represents a person with keys for name, age, and profession. The program should be well-commented and formatted according to PEP 8 guidelines.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nI am not able to write files directly to the disk. Below is the code to create a list of dictionaries, where each dictionary represents a person with keys for name, age, and profession, and then reading that data from a json file, editing and then writing back to the json file.\n\n```python\nimport json\n\nfilename = \"people.json\"\n\n# create a list of people dictionaries\npeople = [\n    {\"name\": \"john doe\", \"age\": 35, \"profession\": \"software engineer\"},\n    {\"name\": \"jane smith\", \"age\": 25, \"profession\": \"data analyst\"},\n    {\"name\": \"bob johnson\", \"age\": 40, \"profession\": \"medical doctor\"}\n]\n\n# write the people list to a json file\nwith open(filename, \"w\") as file:\n    json.dump(people, file, indent=4)\n\n# read the people list from the json file\nwith open(filename) as file:\n    # use json.load() to convert the json data into a list of dictionaries\n    people = json.load(file)\n\n# update the profession of the first person in the list\npeople[0][\"profession\"] = \"data scientist\"\n\n# write the updated people list back to the json file\nwith open(filename, \"w\") as file:\n    json.dump(people, file, indent=4)\n```\n\nin the above code, we first create a list of people dictionaries and write it to a json file using the `json.dump()` function. We then read the same data from the json file into the `people` list using the `json.load()` function. We then update the profession of the first person in the list and write the updated `people` list back to the json file using the `json.dump()` function. \n\nnote that we have used the `with` statement in all three `open()` functions. This ensures that the file is properly closed after use and that any changes made to the file are saved. Also, we have used the `indent=4` option to make the data in the json file more readable.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nCould you provide some additional information about how to access specific elements within the list of dictionaries in the JSON file? For example, how would I access the age of the second person in the list?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nCertainly! To access specific elements in the list of dictionaries, you can first use the `json.load()` function to read the data from the JSON file and store it in a Python variable. Then, you can access individual elements in the list using indexing and dictionary key access.\n\nHere's an example of how you could access the age of the second person in the list:\n\n```python\nimport json\n\nfilename = \"people.json\"\n\n# Read the people list from the JSON file\nwith open(filename) as file:\n    people = json.load(file)\n\n# Access the age of the second person in the list\nage_of_second_person = people[1][\"age\"]\n\nprint(age_of_second_person) # Output: 25\n```\n\nIn this example, we read the data from the `\"people.json\"` file into the `people` variable using `json.load()`. We then access the age of the second person in the list (which has an index of 1, since Python indexes start at 0) using `people[1][\"age\"]`. We store this value in the `age_of_second_person` variable, and then print it to the console.\n\nSimilarly, you can access other elements in the list using indexing and dictionary key access. For example, to access the name of the third person in the list, you could use `people[2][\"name\"]`.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThis is very helpful! Could you provide more examples of how we can manipulate the data in the JSON file? For instance, how can we add a new person to the list or remove an existing person?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nSure, I can definitely provide some examples of how to manipulate the data in the JSON file. To add a new person to the list, you can simply create a new dictionary with the person's information, and then append it to the `people` list. Here's an example:\n\n```python\nimport json\n\nfilename = \"people.json\"\n\n# Read the people list from the JSON file\nwith open(filename) as file:\n    people = json.load(file)\n\n# Add a new person to the list\nnew_person = {\"name\": \"Alice Adams\", \"age\": 30, \"profession\": \"Marketing Manager\"}\npeople.append(new_person)\n\n# Write the updated people list back to the JSON file\nwith open(filename, \"w\") as file:\n    json.dump(people, file, indent=4)\n```\n\nIn this example, we first read the data from the `\"people.json\"` file into the `people` variable using `json.load()`. We then create a new dictionary called `new_person` with the information for the new person we want to add. We append this `new_person` dictionary to the `people` list using the `append()` function. Finally, we write the updated `people` list back to the JSON file using `json.dump()`. To remove an existing person from the list, you can use the `pop()` function to remove the dictionary at a specific index. Here's an example:\n\n```python\nimport json\n\nfilename = \"people.json\"\n\n# Read the people list from the JSON file\nwith open(filename) as file:\n    people = json.load(file)\n\n# Remove the second person from the list\npeople.pop(1)\n\n# Write the updated people list back to the JSON file\nwith open(filename, \"w\") as file:\n    json.dump(people, file, indent=4)\n```\n\nIn this example, we first read the data from the `\"people.json\"` file into the `people` variable using `json.load()`. We then use `pop(1)` to remove the second person in the list (since Python indexes start at 0, the second person has an index of 1). We then write the updated `people` list back to the JSON file using `json.dump()`. Note that you could also remove a dictionary from the `people` list using other methods like `remove()` or slicing, depending on your needs.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nThis is all very helpful! Could you add some information on how we can sort the list of dictionaries based on a specific key, such as age or name? And can we also sort it in reverse order?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nCertainly! To sort the list of dictionaries based on a specific key, such as `age` or `name`, you can use the `sorted()` function with a `key` argument that specifies the key to use for sorting. You can also use the `reverse` argument to sort the list in reverse order. Here's an example:\n\n```python\nimport json\n\nfilename = \"people.json\"\n\n# Read the people list from the JSON file\nwith open(filename) as file:\n    people = json.load(file)\n\n# Sort the people list by age in ascending order\npeople_sorted_by_age = sorted(people, key=lambda person: person[\"age\"])\n\n# Sort the people list by name in descending order\npeople_sorted_by_name_reverse = sorted(people, key=lambda person: person[\"name\"], reverse=True)\n\n# Print the sorted people lists\nprint(\"People sorted by age:\")\nprint(people_sorted_by_age)\nprint(\"\\nPeople sorted by name (in reverse order):\")\nprint(people_sorted_by_name_reverse)\n```\n\nIn this example, we first read the data from the `\"people.json\"` file into the `people` variable using `json.load()`. We then use the `sorted()` function with a `key` argument to sort the `people` list based on the `age` key. The `key` argument is a lambda function that specifies the key to use for sorting, in this case `person[\"age\"]`. Since we don't specify a `reverse` argument, the list will be sorted in ascending order by default. We then use the `sorted()` function again to sort the `people` list based on the `name` key, this time specifying the `reverse` argument to sort the list in descending order. Finally, we print the sorted `people` lists to the console. Note that the `key` argument can be any function that takes a single argument (each dictionary in this case) and returns a value to use for sorting. So you can use any key you want, including ones that you define yourself. Also note that the sorting is done in-place, meaning the original list is modified. If you want to keep the original list unchanged, you can create a copy of the list first using the `copy()` or `list()` functions.<|eot_id|>\n#####################################\nSample 251 of the processed training set:\n\n<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nCreate a Python program that prompts the user to input the longitude and latitude coordinates of two cities and calculates the distance between them using the Haversine formula. The program should output the distance in miles or kilometers, depending on the user's preference, and also inform the user the estimated time it would take to travel from one city to another assuming a constant speed. The program should be written in a modular and readable style, with clear variable names and comments to explain the logic behind each step. It should also include error handling for incorrect user inputs and appropriate unit conversions.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n# Import necessary libraries and functions for calculating distances and converting units\nfrom math import radians, cos, sin, asin, sqrt\nfrom datetime import timedelta\n\n# Define function to prompt user for city coordinates\ndef get_coordinates(city_number):\n    \"\"\"Prompt user for latitude and longitude coordinates of a city.\"\"\"\n    while True:\n        try:\n            lat = float(input(f\"Enter the latitude of city {city_number} (positive for north, negative for south): \"))\n            long = float(input(f\"Enter the longitude of city {city_number} (positive for east, negative for west): \"))\n            return lat, long\n        except ValueError:\n            print(\"Please enter a valid numerical latitude and longitude value.\")\n\n# Define function to calculate great circle distance between two points using Haversine formula\ndef calculate_distance(lat1, long1, lat2, long2):\n    \"\"\"Calculate the great circle distance between two points using the Haversine formula.\"\"\"\n    # Convert all coordinates from degrees to radians\n    lat1, long1, lat2, long2 = map(radians, [lat1, long1, lat2, long2])\n\n    # Calculate the differences between the latitudes and longitudes\n    dlat = lat2 - lat1\n    dlong = long2 - long1\n\n    # Apply the Haversine formula\n    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlong / 2) ** 2\n    c = 2 * asin(sqrt(a))\n    r = 3956  # Radius of the earth in miles\n    distance_in_miles = c * r\n\n    return distance_in_miles\n\n# Define function to convert miles to kilometers\ndef convert_to_km(miles):\n    \"\"\"Convert miles to kilometers.\"\"\"\n    return miles * 1.609344\n\n# Define function to calculate estimated travel time based on distance and speed\ndef calculate_travel_time(distance, speed):\n    \"\"\"Calculate estimated travel time based on distance and speed.\"\"\"\n    # Convert distance from miles to kilometers\n    distance_in_km = convert_to_km(distance)\n    # Calculate estimated travel time based on distance and speed\n    travel_time = timedelta(hours=(distance_in_km / speed))\n    return travel_time\n\n# Prompt user for city coordinates and calculate distance between them\nprint(\"Welcome to the City Distance Calculator!\")\ncity1_lat, city1_long = get_coordinates(1)\ncity2_lat, city2_long = get_coordinates(2)\ndistance_in_miles = calculate_distance(city1_lat, city1_long, city2_lat, city2_long)\n\n# Prompt user for preferred unit of measurement (miles or kilometers)\nwhile True:\n    unit = input(\"Do you want the result in miles or kilometers? \").lower()\n    if unit == \"miles\":\n        print(f\"The distance between the cities is {distance_in_miles:.2f} miles.\")\n        break\n    elif unit == \"kilometers\":\n        distance_in_km = convert_to_km(distance_in_miles)\n        print(f\"The distance between the cities is {distance_in_km:.2f} kilometers.\")\n        break\n    else:\n        print(\"Please enter 'miles' or 'kilometers'.\")\n\n# Prompt user for speed and calculate estimated travel time\nwhile True:\n    try:\n        speed = float(input(\"Enter the average speed of travel in miles per hour: \"))\n        travel_time = calculate_travel_time(distance_in_miles, speed)\n        print(f\"Assuming a constant speed of {speed:.2f} miles per hour, it would take {travel_time}.\")\n        break\n    except ValueError:\n        print(\"Please enter a valid numerical speed value in miles per hour.\")<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nCould you please add some explanation about the Haversine formula and how it calculates the distance between two points?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nSure! The Haversine formula is a mathematical formula used to calculate the shortest distance between two points on the surface of a sphere, such as the Earth. It takes into account the curvature of the Earth and the fact that it is not a perfect sphere, but rather an oblate spheroid. To calculate the distance using Haversine formula, we first convert the latitude and longitude coordinates of both cities from degrees to radians. Then we calculate the differences between the latitudes and longitudes of the two cities. We apply the Haversine formula using these differences to calculate the great circle distance between the two cities in miles. The formula itself uses the trigonometric functions sine and cosine to calculate the distance between two points on the surface of a sphere, based on the angles between the two points and the center of the sphere. The formula involves taking the inverse sine and using the square root function to calculate the distance. Overall, the Haversine formula is a very accurate way of calculating distances over relatively short distances on the Earth's surface.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nCould you also add some information about the limitations of using this formula for measuring distances between cities?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nCertainly! While the Haversine formula is a great way to calculate distances between cities on the surface of a sphere, there are some limitations to this approach which are worth discussing. Firstly, when calculating distances between two cities, we assume a perfect sphere, which means the Earth's oblateness and its terrain are ignored. This is not a major issue when measuring distances over relatively short distances, but as the distance between the two points increases, the effects related to the oblateness of the earth and the interference from complicated terrain might become significant. Therefore, for more geological applications, it is necessary to use more accurate mathematical models that account for these factors. Secondly, the Haversine formula does not take into account things like atmospheric conditions, wind speed and direction, and other factors that could impact the actual travel time between two cities. Therefore, the estimated travel time calculated by assuming constant speed might not be very accurate in real-life scenarios. In summary, the Haversine formula is a great starting point for those who want to learn more about calculating distances between cities, but its limitations should be kept in mind when considering real-life applications that demand higher accuracy.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nCould you also provide some details about more accurate mathematical models that can be used to measure distances between cities, especially for geological applications?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nCertainly! There are more complex models that can be used to measure distances between cities with higher degrees of accuracy. However, these models take into account the Earth's oblateness and terrain's toporaphy, which are beyond the scope of the Haversine formula. One such model that is often used in geodesy and geological applications is called the Vincenty's formula. This formula uses a more complex mathematical approach to calculate the distance between two points on an oblate spheroid, and is more accurate than the Haversine formula. The Vincenty's formula considers the fact that the Earth is not a perfect sphere but is an oblate spheroid by using an ellipsoidal model, and takes into account factors like the flattening of the Earth's polar regions and the variation of the Earth's radius at different latitudes. This formula also considers the actual path taken between two points, taking into account the topology of the terrain, which makes it even more accurate. The Vincenty's formula is more complex than the Haversine formula and may require more computation time. However, it is the go-to choice for accurate distance calculations in geodesy and many other geological applications.<|eot_id|>\n#####################################\nSample 218 of the processed training set:\n\n<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nGiven the text: Express your love and affection for your loved one with this cutest Mixed Roses N Cookies. Yes, this loveable flower bunch is of mixed varieties of color roses with the cookies combo can make your dear one to wonder. So, buy this lovable bunch to make smile on her face.\nCan you suggest any add-ons to make this Mixed Roses N Cookies gift more personalized?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n1. A handwritten love letter or card expressing your feelings for your loved one.\n2. A personalized photo frame with a picture of you both together.\n3. A teddy bear or stuffed animal to add an extra touch of cuteness.\n4. A beautiful piece of jewelry, such as a necklace or bracelet, to show your continued love and commitment.\n5. A bottle of your loved one's favorite perfume or cologne to make them feel special and loved.\n6. A box of chocolates or other sweet treats to add to the cookies and make it a full dessert experience.\n7. A romantic movie or book to enjoy together as part of a cozy night in.\n8. A special candle with a relaxing scent to create a calming and romantic atmosphere.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nCan you help me purchase the Mixed Roses N Cookies gift? What site can I buy it from?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nI do not have access to any specific websites or information about your location. However, you can try searching for \"mixed roses n cookies\" on popular online gift shops such as amazon, etsy or ferns n petals, depending on your location. Alternatively, you can also search for local florists or gift shops in your area or ask for recommendations from friends or family.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nCan you give me an estimate of how much the Mixed Roses N Cookies gift would cost?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nI do not have access to pricing information for any particular gift shop or florist. The cost of a mixed roses n cookies gift will depend on factors such as the number of roses in the bunch, the type of cookies included, the location where you plan to purchase the gift, and any additional personalization or add-ons you choose. To get an estimate, you can try searching for \"mixed roses n cookies\" on popular online gift shops and florists, or you can contact a local florist or gift shop for pricing information.<|eot_id|>\n#####################################\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BitsAndBytesConfig\nimport torch\n\n# specify how to quantize the model\nquantization_config = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_use_double_quant=True,\n            bnb_4bit_quant_type=\"nf4\",\n            bnb_4bit_compute_dtype=torch.bfloat16,\n)\ndevice_map = \"auto\"#{\"\": torch.cuda.current_device()} if torch.cuda.is_available() else None\n\nmodel_kwargs = dict(\n#     attn_implementation=False,#\"flash_attention_2\", # set this to True if your GPU supports it (Flash Attention drastically speeds up model computations)\n    torch_dtype=\"auto\",\n    use_cache=False, # set to False as we're going to use gradient checkpointing\n    device_map=device_map,\n    quantization_config=quantization_config,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:39:52.077587Z","iopub.execute_input":"2024-04-26T19:39:52.077918Z","iopub.status.idle":"2024-04-26T19:39:52.093545Z","shell.execute_reply.started":"2024-04-26T19:39:52.077893Z","shell.execute_reply":"2024-04-26T19:39:52.092697Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom peft import LoraConfig\nfrom transformers import TrainingArguments","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:39:52.094764Z","iopub.execute_input":"2024-04-26T19:39:52.095044Z","iopub.status.idle":"2024-04-26T19:40:01.689904Z","shell.execute_reply.started":"2024-04-26T19:39:52.095014Z","shell.execute_reply":"2024-04-26T19:40:01.688994Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"2024-04-26 19:39:56.316225: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-26 19:39:56.316296: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-26 19:39:56.322609: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:40:01.691380Z","iopub.execute_input":"2024-04-26T19:40:01.692249Z","iopub.status.idle":"2024-04-26T19:40:01.697471Z","shell.execute_reply.started":"2024-04-26T19:40:01.692209Z","shell.execute_reply":"2024-04-26T19:40:01.696372Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# path where the Trainer will save its checkpoints and logs\ntrained_model_id = \"Llama-3-8B-sft-lora-ultrachat\"\noutput_dir = 'kaggle/working/' + trained_model_id\n\n# based on config\ntraining_args = TrainingArguments(\n    fp16=False, # specify bf16=True instead when training on GPUs that support bf16 else fp16\n    bf16=False,\n    do_eval=True,\n    evaluation_strategy=\"epoch\",\n    gradient_accumulation_steps=1,\n    gradient_checkpointing=True,\n    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n    learning_rate=2.0e-05,\n    log_level=\"info\",\n    logging_steps=5,\n    logging_strategy=\"steps\",\n    lr_scheduler_type=\"cosine\",\n    max_steps=-1,\n    num_train_epochs=1,\n    output_dir=output_dir,\n    overwrite_output_dir=True,\n    per_device_eval_batch_size=1, # originally set to 8\n    per_device_train_batch_size=1, # originally set to 8\n    push_to_hub=True,\n    hub_model_id=trained_model_id,\n    # hub_strategy=\"every_save\",\n    # report_to=\"tensorboard\",\n    report_to=\"none\",\n    save_strategy=\"no\",\n    save_total_limit=None,\n    seed=42,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:40:01.698803Z","iopub.execute_input":"2024-04-26T19:40:01.699149Z","iopub.status.idle":"2024-04-26T19:40:01.747796Z","shell.execute_reply.started":"2024-04-26T19:40:01.699121Z","shell.execute_reply":"2024-04-26T19:40:01.746390Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# based on config\npeft_config = LoraConfig(\n        r=64,\n        lora_alpha=16,\n        lora_dropout=0.1,\n        bias=\"none\",\n        task_type=\"CAUSAL_LM\",\n        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:40:01.749440Z","iopub.execute_input":"2024-04-26T19:40:01.749835Z","iopub.status.idle":"2024-04-26T19:40:01.755308Z","shell.execute_reply.started":"2024-04-26T19:40:01.749802Z","shell.execute_reply":"2024-04-26T19:40:01.754213Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# del trainer\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:40:01.756633Z","iopub.execute_input":"2024-04-26T19:40:01.757050Z","iopub.status.idle":"2024-04-26T19:40:01.768077Z","shell.execute_reply.started":"2024-04-26T19:40:01.757013Z","shell.execute_reply":"2024-04-26T19:40:01.766845Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"trainer = SFTTrainer(\n        model=model_id,\n        model_init_kwargs=model_kwargs,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=eval_dataset,\n        dataset_text_field=\"text\",\n        tokenizer=tokenizer,\n        packing=True,\n        peft_config=peft_config,\n        max_seq_length=tokenizer.model_max_length,\n    )","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:40:01.769949Z","iopub.execute_input":"2024-04-26T19:40:01.770398Z","iopub.status.idle":"2024-04-26T19:41:18.760526Z","shell.execute_reply.started":"2024-04-26T19:40:01.770345Z","shell.execute_reply":"2024-04-26T19:41:18.759710Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:166: UserWarning: You passed a model_id to the SFTTrainer. This will automatically create an `AutoModelForCausalLM` or a `PeftModel` (if you passed a `peft_config`) for you.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7323978b373b4e0a8627cad81f30d60d"}},"metadata":{}},{"name":"stderr","text":"You have loaded a model on multiple GPUs. `is_model_parallel` attribute will be force-set to `True` to avoid any unexpected behavior such as device placement mismatching.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_result = trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:41:18.761807Z","iopub.execute_input":"2024-04-26T19:41:18.762180Z","iopub.status.idle":"2024-04-26T19:42:20.981337Z","shell.execute_reply.started":"2024-04-26T19:41:18.762142Z","shell.execute_reply":"2024-04-26T19:42:20.979711Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"***** Running training *****\n  Num examples = 278\n  Num Epochs = 1\n  Instantaneous batch size per device = 1\n  Total train batch size (w. parallel, distributed & accumulation) = 1\n  Gradient Accumulation steps = 1\n  Total optimization steps = 278\n  Number of trainable parameters = 54,525,952\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3' max='278' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  3/278 00:25 < 1:55:34, 0.04 it/s, Epoch 0.01/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:361\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trl_activate_neftune(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 361\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1850\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1847\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   1849\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 1850\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1851\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1853\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1855\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1856\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1857\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2203\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2202\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2203\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2206\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2209\u001b[0m ):\n\u001b[1;32m   2210\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2211\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3147\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3145\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:2013\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2011\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2012\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2013\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 1 has a total capacty of 14.75 GiB of which 537.06 MiB is free. Process 15312 has 14.22 GiB memory in use. Of the allocated memory 12.65 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 1 has a total capacty of 14.75 GiB of which 537.06 MiB is free. Process 15312 has 14.22 GiB memory in use. Of the allocated memory 12.65 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]},{"cell_type":"code","source":"trainer.push_to_hub()\nprint('Finished')","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:42:20.982491Z","iopub.status.idle":"2024-04-26T19:42:20.982963Z","shell.execute_reply.started":"2024-04-26T19:42:20.982741Z","shell.execute_reply":"2024-04-26T19:42:20.982768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}