{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"https://github.com/NielsRogge/Transformers-Tutorials/blob/master/Mistral/Supervised_fine_tuning_(SFT)_of_an_LLM_using_Hugging_Face_tooling.ipynb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install -U transformers[torch] datasets","metadata":{"execution":{"iopub.status.busy":"2024-04-16T19:22:35.228221Z","iopub.execute_input":"2024-04-16T19:22:35.228661Z","iopub.status.idle":"2024-04-16T19:22:48.066455Z","shell.execute_reply.started":"2024-04-16T19:22:35.228628Z","shell.execute_reply":"2024-04-16T19:22:48.065454Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\nRequirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.28.0)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q bitsandbytes trl peft","metadata":{"execution":{"iopub.status.busy":"2024-04-16T19:22:48.068414Z","iopub.execute_input":"2024-04-16T19:22:48.068737Z","iopub.status.idle":"2024-04-16T19:23:00.459993Z","shell.execute_reply.started":"2024-04-16T19:22:48.068685Z","shell.execute_reply":"2024-04-16T19:23:00.458803Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install flash-attn --no-build-isolation","metadata":{"execution":{"iopub.status.busy":"2024-04-16T19:23:00.461610Z","iopub.execute_input":"2024-04-16T19:23:00.462459Z","iopub.status.idle":"2024-04-16T19:23:12.597016Z","shell.execute_reply.started":"2024-04-16T19:23:00.462416Z","shell.execute_reply":"2024-04-16T19:23:12.595793Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: flash-attn in /opt/conda/lib/python3.10/site-packages (2.5.7)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash-attn) (2.1.2)\nRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from flash-attn) (0.7.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from flash-attn) (21.3)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash-attn) (1.11.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->flash-attn) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash-attn) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\n\n# based on config\nraw_datasets = load_dataset(\"HuggingFaceH4/ultrachat_200k\")","metadata":{"execution":{"iopub.status.busy":"2024-04-16T19:23:12.599900Z","iopub.execute_input":"2024-04-16T19:23:12.600237Z","iopub.status.idle":"2024-04-16T19:23:20.464271Z","shell.execute_reply.started":"2024-04-16T19:23:12.600206Z","shell.execute_reply":"2024-04-16T19:23:20.463375Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from datasets import DatasetDict\n\n# remove this when done debugging\nindices = range(0,100)\n\ndataset_dict = {\"train\": raw_datasets[\"train_sft\"].select(indices),\n                \"test\": raw_datasets[\"test_sft\"].select(indices)}\n\nraw_datasets = DatasetDict(dataset_dict)\nraw_datasets","metadata":{"execution":{"iopub.status.busy":"2024-04-16T19:23:20.465448Z","iopub.execute_input":"2024-04-16T19:23:20.466033Z","iopub.status.idle":"2024-04-16T19:23:20.482377Z","shell.execute_reply.started":"2024-04-16T19:23:20.465996Z","shell.execute_reply":"2024-04-16T19:23:20.481217Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'prompt_id', 'messages'],\n        num_rows: 100\n    })\n    test: Dataset({\n        features: ['prompt', 'prompt_id', 'messages'],\n        num_rows: 100\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets[\"train\"][:2]['messages']","metadata":{"execution":{"iopub.status.busy":"2024-04-16T19:23:20.483463Z","iopub.execute_input":"2024-04-16T19:23:20.483698Z","iopub.status.idle":"2024-04-16T19:23:20.502834Z","shell.execute_reply.started":"2024-04-16T19:23:20.483676Z","shell.execute_reply":"2024-04-16T19:23:20.501980Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"[[{'content': \"These instructions apply to section-based themes (Responsive 6.0+, Retina 4.0+, Parallax 3.0+ Turbo 2.0+, Mobilia 5.0+). What theme version am I using?\\nOn your Collections pages & Featured Collections sections, you can easily show the secondary image of a product on hover by enabling one of the theme's built-in settings!\\nYour Collection pages & Featured Collections sections will now display the secondary product image just by hovering over that product image thumbnail.\\nDoes this feature apply to all sections of the theme or just specific ones as listed in the text material?\",\n   'role': 'user'},\n  {'content': 'This feature only applies to Collection pages and Featured Collections sections of the section-based themes listed in the text material.',\n   'role': 'assistant'},\n  {'content': 'Can you guide me through the process of enabling the secondary image hover feature on my Collection pages and Featured Collections sections?',\n   'role': 'user'},\n  {'content': \"Sure, here are the steps to enable the secondary image hover feature on your Collection pages and Featured Collections sections:\\n\\n1. Log in to your Shopify account and go to your Online Store.\\n2. Click on Customize theme for the section-based theme you are using.\\n3. Navigate to the Collection pages or Featured Collections section where you want to enable the secondary image hover feature.\\n4. With the section open, click on the section's setting (gear) icon in the top-left corner.\\n5. In the settings panel that appears, look for an option labeled 'Image display' or 'Image hover'.\\n6. If available, select 'Show secondary image on hover'.\\n7. Save the changes and preview the Collection/Featured Collection page to see the effect.\\n\\nIf you're having trouble finding the setting, the best thing to do is refer to your theme's documentation, since the location and labeling of settings can vary between themes.\",\n   'role': 'assistant'},\n  {'content': 'Can you provide me with a link to the documentation for my theme?',\n   'role': 'user'},\n  {'content': \"I don't have access to your store's theme information. However, you can usually find the documentation for your theme by going to the shopify theme store, finding your theme and clicking on the 'support' link located in the bottom right corner of the page. Alternatively, you can do a google search for the name of your theme followed by 'documentation' or 'user guide'.\",\n   'role': 'assistant'},\n  {'content': 'Can you confirm if this feature also works for the Quick Shop section of my theme?',\n   'role': 'user'},\n  {'content': \"The secondary image hover feature may or may not work for your Quick Shop section, depending on the configuration of your theme. Some themes include this feature in the Quick Shop section by default, while others may require additional customization. To check if this feature is available for the Quick Shop section of your theme, follow these steps:\\n\\n1. Go to the Quick Shop section where you would like to enable the feature. 2. Click on the Quick Shop settings icon (gear icon) and look for 'Image display' or 'Image hover'. 3. If available, select 'Show secondary image on hover'. 4. Save the changes. If this option is not available in your Quick Shop section settings, you may need to reach out to your theme developer for assistance with customizing your Quick Shop section to include this feature.\",\n   'role': 'assistant'}],\n [{'content': 'Which famous landmarks should I visit in London, beyond the usual ones?',\n   'role': 'user'},\n  {'content': \"1. Leadenhall Market - a beautiful indoor market with stunning Victorian architecture, also used as a filming location in the Harry Potter films.\\n\\n2. St. Dunstan in the East - a ruined church in the middle of the city that has been turned into a beautiful public garden.\\n\\n3. The Monument - a 202-foot-tall column commemorating the Great Fire of London, with a staircase leading to a viewing platform offering great views of the city.\\n\\n4. The Camden Town Markets - an eclectic collection of markets offering food, fashion, and vintage items, plus live music and street performers.\\n\\n5. Novelist's House - the former home of Charles Dickens, now a museum dedicated to his life and works.\\n\\n6. The Old Operating Theatre - a museum housed in the oldest surviving operating theatre in Europe, with exhibits on the history of surgery and medical practices.\\n\\n7. The Churchill War Rooms - an underground complex used as a British government command centre during World War II, now a museum dedicated to Winston Churchill and his leadership during the war.\\n\\n8. The Brunel Museum - a museum dedicated to the life and works of engineer Isambard Kingdom Brunel, with exhibitions on his revolutionary designs for bridges, ships, and tunnels.\\n\\n9. The Clink Prison Museum - a museum in the former site of the notorious medieval prison, with exhibits on the history of crime and punishment in London.\\n\\n10. The Royal Observatory Greenwich - an observatory and museum dedicated to astronomy and navigation, with exhibits on the history of timekeeping and space exploration.\",\n   'role': 'assistant'},\n  {'content': \"Hmm, those are interesting suggestions, but I've already seen so many touristy landmarks in London. Is there something more offbeat that you can recommend? Something that locals might know about?\",\n   'role': 'user'},\n  {'content': \"Absolutely! Here are some offbeat and lesser-known things to see in London that locals might recommend:\\n\\n1. God's Own Junkyard - a neon wonderland filled with vintage and new neon signs.\\n\\n2. Hornsey Town Hall Arts Centre - a grade II listed building with a rich history and home to many art exhibitions and events.\\n\\n3. Clapham Grand - a historic Victorian theatre that has been transformed into a music venue, cinema and a comedy club.\\n\\n4. Gordon Museum of Pathology - the pathology museum of King's College in London that holds a collection of over 8,000 medical specimens.\\n\\n5. John Soane's Museum - the former home of wealthy architect John Soane is a museum with eclectic collections of paintings, sculptures, and curiosities.\\n\\n6. The Viktor Wynd Museum of Curiosities - a small museum filled with strange and unusual objects, taxidermy, and rare books.\\n\\n7. The Cross Bones Graveyard - a medieval graveyard that became known as an outcast cemetery with a history connected to the sex industry, now a memorial garden.\\n\\n8. Highgate Cemetery - a beautiful Victorian graveyard known for its Gothic architecture and where many famous people, including Karl Marx, are buried.\\n\\n9. Dalston Eastern Curve Garden - a beautiful community garden near the Dalston Junction station that is run by volunteers and has regular events.\\n\\n10. The Geffrye Museum of the Home - a museum that explores the history of domestic interiors in England, with a beautiful garden and regular market events.\\n\\nThere are many other hidden gems in London, and a quick Google search for ‘offbeat things in London’ will bring up many blogs and resources with more options.\",\n   'role': 'assistant'},\n  {'content': \"Wow, these offbeat suggestions are really interesting. I had no idea there were so many unique things to see in London. Thanks for the recommendations, you're much more helpful than I expected. Can you tell me more about the Viktor Wynd Museum of Curiosities? It sounds like my kind of place.\",\n   'role': 'user'},\n  {'content': \"Sure! The Viktor Wynd Museum of Curiosities, Fine Art & Natural History is a small museum located in Hackney, East London. The museum, founded by collector Viktor Wynd is a place where you can find taxidermy, books, anatomical models, and other curiosities. The museum is famous for its collection of shrunken heads, dodo bones, and the famous mermaid. It is also notable for its dimly lit, atmospheric decor, and its bar which serves cocktails and allows visitors to take drinks into the museum. The museum is open daily except for Mondays and Tuesdays, and it also frequently hosts events and exhibitions, so be sure to check the museum's website to see what's on.\",\n   'role': 'assistant'},\n  {'content': \"Woah, the Viktor Wynd Museum sounds like a wacky and fun place to visit. I don't think I've ever seen a shrunken head before. I wonder what kind of cocktails they serve there... Maybe I can convince some friends to check it out with me!\",\n   'role': 'user'},\n  {'content': 'Yes, the museum is definitely one of the more unusual places to visit in London! The cocktail menu at Viktor Wynd\\'s bar is just as eclectic as the museum\\'s collection, featuring brightly colored cocktails inspired by the exhibits, such as the \"Shrunken Head\" or \"Mermaid Tail\" cocktails. The museum and bar are on the smaller side, so it would make for a unique and intimate outing with friends. If you\\'re looking for something different and memorable to do in London, the Viktor Wynd Museum is definitely worth checking out!',\n   'role': 'assistant'},\n  {'content': \"Whoa, a bar in a museum?! That's wild. I'm definitely going to have to try one of those cocktails. Do you think they have anything with a shrunken head as a garnish? That would be a trip.\",\n   'role': 'user'},\n  {'content': \"I am not sure if the Viktor Wynd Museum of Curiosities serves cocktails with an actual shrunken head as a garnish. However, they might have some creative cocktails that incorporate a shrunken head replica or something similar as an element in the drink. Nevertheless, the bar offers a unique setting and a cocktail menu that includes some unusual ingredients so it's definitely worth checking out! It's likely to be an eccentric and memorable experience, and I'm sure you'll have a great time there with your friends.\",\n   'role': 'assistant'},\n  {'content': 'I can\\'t wait to see that mermaid at the Viktor Wynd Museum. I wonder if it\\'s real or just a replica. Either way, it\\'s bound to be a fascinating item to behold. And I\\'ll make sure to order that \"Mermaid Tail\" cocktail while I\\'m there!',\n   'role': 'user'},\n  {'content': 'Yes, the mermaid at the Viktor Wynd Museum of Curiosities is definitely one of its most famous exhibits. It\\'s actually a recreation made from the skeleton of a monkey and the tail of a fish, so it\\'s not a real mermaid of course, but it\\'s still an intriguing piece. The museum has many other curiosities to discover as well, and the atmosphere there is unlike anything you\\'ll find in other museums. And don\\'t forget to try that \"Mermaid Tail\" cocktail - it\\'s the perfect accompaniment to the museum\\'s quirky vibe!',\n   'role': 'assistant'}]]"},"metadata":{}}]},{"cell_type":"code","source":"example = raw_datasets[\"train\"][0]\nmessages = example[\"messages\"]\nfor message in messages:\n  role = message[\"role\"]\n  content = message[\"content\"]\n  print('{0:20}:  {1}'.format(role, content))","metadata":{"execution":{"iopub.status.busy":"2024-04-16T19:23:20.504018Z","iopub.execute_input":"2024-04-16T19:23:20.504280Z","iopub.status.idle":"2024-04-16T19:23:20.514169Z","shell.execute_reply.started":"2024-04-16T19:23:20.504257Z","shell.execute_reply":"2024-04-16T19:23:20.513308Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"user                :  These instructions apply to section-based themes (Responsive 6.0+, Retina 4.0+, Parallax 3.0+ Turbo 2.0+, Mobilia 5.0+). What theme version am I using?\nOn your Collections pages & Featured Collections sections, you can easily show the secondary image of a product on hover by enabling one of the theme's built-in settings!\nYour Collection pages & Featured Collections sections will now display the secondary product image just by hovering over that product image thumbnail.\nDoes this feature apply to all sections of the theme or just specific ones as listed in the text material?\nassistant           :  This feature only applies to Collection pages and Featured Collections sections of the section-based themes listed in the text material.\nuser                :  Can you guide me through the process of enabling the secondary image hover feature on my Collection pages and Featured Collections sections?\nassistant           :  Sure, here are the steps to enable the secondary image hover feature on your Collection pages and Featured Collections sections:\n\n1. Log in to your Shopify account and go to your Online Store.\n2. Click on Customize theme for the section-based theme you are using.\n3. Navigate to the Collection pages or Featured Collections section where you want to enable the secondary image hover feature.\n4. With the section open, click on the section's setting (gear) icon in the top-left corner.\n5. In the settings panel that appears, look for an option labeled 'Image display' or 'Image hover'.\n6. If available, select 'Show secondary image on hover'.\n7. Save the changes and preview the Collection/Featured Collection page to see the effect.\n\nIf you're having trouble finding the setting, the best thing to do is refer to your theme's documentation, since the location and labeling of settings can vary between themes.\nuser                :  Can you provide me with a link to the documentation for my theme?\nassistant           :  I don't have access to your store's theme information. However, you can usually find the documentation for your theme by going to the shopify theme store, finding your theme and clicking on the 'support' link located in the bottom right corner of the page. Alternatively, you can do a google search for the name of your theme followed by 'documentation' or 'user guide'.\nuser                :  Can you confirm if this feature also works for the Quick Shop section of my theme?\nassistant           :  The secondary image hover feature may or may not work for your Quick Shop section, depending on the configuration of your theme. Some themes include this feature in the Quick Shop section by default, while others may require additional customization. To check if this feature is available for the Quick Shop section of your theme, follow these steps:\n\n1. Go to the Quick Shop section where you would like to enable the feature. 2. Click on the Quick Shop settings icon (gear icon) and look for 'Image display' or 'Image hover'. 3. If available, select 'Show secondary image on hover'. 4. Save the changes. If this option is not available in your Quick Shop section settings, you may need to reach out to your theme developer for assistance with customizing your Quick Shop section to include this feature.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# model_id = \"mistralai/Mistral-7B-v0.2\"\nmodel_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\n\n# set pad_token_id equal to the eos_token_id if not set\nif tokenizer.pad_token_id is None:\n  tokenizer.pad_token_id = tokenizer.eos_token_id\n\n# Set reasonable default for models without max length\nif tokenizer.model_max_length > 100_000:\n  tokenizer.model_max_length = 2048\n\n# Set chat template\nDEFAULT_CHAT_TEMPLATE = \"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\"\ntokenizer.chat_template = DEFAULT_CHAT_TEMPLATE","metadata":{"execution":{"iopub.status.busy":"2024-04-16T19:23:20.515327Z","iopub.execute_input":"2024-04-16T19:23:20.515652Z","iopub.status.idle":"2024-04-16T19:23:24.744385Z","shell.execute_reply.started":"2024-04-16T19:23:20.515621Z","shell.execute_reply":"2024-04-16T19:23:24.743551Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import re\nimport random\nfrom multiprocessing import cpu_count\n\ndef apply_chat_template(example, tokenizer):\n    messages = example[\"messages\"]\n    # We add an empty system message if there is none\n    if messages[0][\"role\"] != \"system\":\n        messages.insert(0, {\"role\": \"system\", \"content\": \"\"})\n    example[\"text\"] = tokenizer.apply_chat_template(messages, tokenize=False)\n\n    return example\n\ncolumn_names = list(raw_datasets[\"train\"].features)\nraw_datasets = raw_datasets.map(apply_chat_template,\n                                num_proc=cpu_count(),\n                                fn_kwargs={\"tokenizer\": tokenizer},\n                                remove_columns=column_names,\n                                desc=\"Applying chat template\",)\n\n# create the splits\ntrain_dataset = raw_datasets[\"train\"]\neval_dataset = raw_datasets[\"test\"]\n\nfor index in random.sample(range(len(raw_datasets[\"train\"])), 3):\n  print(f\"Sample {index} of the processed training set:\\n\\n{raw_datasets['train'][index]['text']}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-16T19:23:24.745517Z","iopub.execute_input":"2024-04-16T19:23:24.745988Z","iopub.status.idle":"2024-04-16T19:23:24.856767Z","shell.execute_reply.started":"2024-04-16T19:23:24.745959Z","shell.execute_reply":"2024-04-16T19:23:24.855767Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Sample 46 of the processed training set:\n\n<|system|>\n</s>\n<|user|>\nWrite a character-driven short story that essentially deals with the theme of social media addiction and delve into the psychological effects that it could have on young minds. Pay close attention to the character arc of the protagonist, portraying how their mental health takes a hit as they struggle to cope with the pressures and the incessant demands of the virtual world. You can depict the impact of social media addiction on various aspects of their life, including their relationships, academics, and self-esteem. Use descriptive language and vivid imagery to make the reader connect with the character on an emotional level.</s>\n<|assistant|>\nZoey had always been a shy and introverted girl, content with the company of books and the occasional online video game. But in high school, she discovered the thrill of social media - the likes, the comments, the validation that came with every post. Before she knew it, she was checking her phone every few minutes, scrolling through her feeds, and comparing herself to the hundreds of happy, perfect strangers online.\n\nAt first, Zoey's addiction was harmless. She posted pictures of her cat, funny memes, and shared her thoughts on the latest movies and TV shows. But as her followers grew, so did her anxiety. She started second-guessing every post, obsessively editing her captions, and deleting anything that didn't get enough likes.\n\nSoon, social media became Zoey's whole world. She spent hours hunched over her phone, scrolling through endless feeds, and skipping meals and homework. She stopped reading books, stopped hanging out with her few real-life friends, and lost interest in everything except the virtual world.\n\nSlowly, her mental health began to suffer. Zoey became irritable, anxious, and depressed. She dreaded going to school, where every interaction felt like another opportunity to be judged, compared, and found lacking. She started skipping class, avoiding her teachers and classmates, and spending all her time online.\n\nAs her grades slipped and her parents grew worried, Zoey felt like she was drowning. She reached out to a few online friends for comfort, but they were as fleeting and insubstantial as the likes on her posts. She started posting more and more desperate messages, hoping for someone to notice her pain and help her out of the virtual hole she had dug herself into.\n\nBut no one did. And soon, Zoey realized that she was alone in her addiction, and it was up to her to break free.\n\nIt wasn't easy. Zoey had to delete all her social media accounts, unfollow all her virtual friends, and face the real world for the first time in a long time. But with the help of her parents, a therapist, and a few trusted friends, she slowly started to rebuild her life.\n\nIt was a slow process. Zoey had to learn how to be present in the moment, how to find joy in real-life interactions, and how to be kind to herself without the constant validation of social media. But day by day, she became stronger, happier, and more at peace.\n\nIn the end, Zoey realized that social media addiction was just a symptom of a deeper problem - a lack of self-esteem, confidence, and authenticity. And as she worked through those issues, she found that she didn't need the virtual world to be happy, after all. She had the real world, full of messy, imperfect, wonderful people, waiting for her to explore and discover. And for the first time in a long time, Zoey was excited to be part of it.</s>\n<|user|>\nThis story is a good start, but I feel like there could be more details about how Zoey's addiction affected her relationships with her family and friends. Can you add some more information about that?</s>\n<|assistant|>\nAbsolutely. As Zoey's social media addiction grew, she became more and more isolated from the people in her life who mattered most. Her parents noticed that she was spending less time with them, and when they tried to bring up their concerns, Zoey became defensive and argued with them. She stopped going on family outings, missing out on holidays, birthdays, and other important events. She became distant and cold around her few remaining friends, who felt like Zoey was more interested in her virtual followers than in real-life relationships.\n\nOver time, this isolation only deepened Zoey's sense of loneliness and despair. She felt like she was trapped in a virtual bubble, unable to reach out to anyone for help or support. And when she finally hit rock bottom, it was clear that her addiction had taken a toll on every aspect of her life - from her family and friendships to her mental and physical health.\n\nIt was only when Zoey recognized the impact that her addiction was having on her relationships that she was able to seek help and turn her life around. She apologized to her parents and friends, and slowly started to rebuild those relationships brick by brick. And as she did so, she began to realize just how important those connections were - and how much happier and healthier she felt when she was fully engaged with the people she loved in real time and in real life.</s>\n\nSample 97 of the processed training set:\n\n<|system|>\n</s>\n<|user|>\nWho can ever forget the legendary TV sitcom Sarabhai vs Sarabhai! I know you've missed them all way too much, especially Rosech. So here's a little treat for you...some of Rosech most unforgettable and insanely hilarious poems just to make your day. Seriously LOL!\n1. When he wrote a victory poem for 'Momma'!\n5. The mystery of the ‘Laal Lagul Jelly’! Can you generate a continuation of the mystery of 'Laal Lagul Jelly' based on Rosech's poem?</s>\n<|assistant|>\n2. His ode to his beloved fridge, ‘Frosty’\n3. The ballad of his pet cockroach, ‘Cocky’\n4. His epic poem on the horrors of going to the dentist\n6. The tragedy of ‘Leftover Daal’ – a heart-wrenching poem about never wanting to eat daal again\n7. His hilarious take on the ‘Bermuda Triangle’ – titled ‘The Bermuda Dangal’!\n8. His ode to ‘Pyjamas’ – the cosiest attire of all time\n9. The tale of his disastrous attempt at cooking, ‘Burnt Roti Blues’\n10. A chilling poem about his fear of ‘Kela’, the demonic banana.</s>\n<|user|>\nThese poems are hilarious! can you compile a list of the most popular episodes of Sarabhai vs Sarabhai?</s>\n<|assistant|>\nSure, here are the top 5 most popular episodes of Sarabhai vs Sarabhai:\n\n1. Monisha ki Mannat – In this episode, Monisha buys an expensive luxury apartment and the others make fun of her for her superstitions.\n\n2. Sahil meets his match – Sahil gets into a battle of wits with a female lawyer who refuses to back down.\n\n3. Maya's class reunion – Maya reunites with her old classmates and finds out that she is not as successful as she thought she was.\n\n4. Rosesh's poems – In this episode, Rosesh showcases his hilarious and often nonsensical poems to his family.\n\n5. The idol theft – The family gets embroiled in a case of idol theft and Maya takes it upon herself to solve the case.\n\nThese episodes are fan favorites and are remembered even today for their witty dialogues and amazing performances by the cast.</s>\n<|user|>\nI'm curious about monisha's luxury apartment. Can you give me a brief description of what it looked like and where it was located?</s>\n<|assistant|>\nSure! Monisha's luxury apartment in Sarabhai vs Sarabhai was located in the famous Mumbai suburb of Malabar Hill. It was a lavish apartment with luxurious fittings and eye-catching decor ranging from ancient Indian Gods to modern art. The living room was huge, had a large French window, and was filled with an assortment of eclectic art pieces. There was also a private balcony with a stunning ocean view. Monisha's apartment was the envy of the Sarabhai family, and they frequently visited it to make fun of her superstitions and enjoy the luxury ambiance.</s>\n\nSample 87 of the processed training set:\n\n<|system|>\n</s>\n<|user|>\nWrite a news article covering the latest advancements in space exploration. Your article should include recent discoveries, technological developments, and scientific breakthroughs. Use a formal and objective writing style and interview experts in the field for additional insights. The article should also discuss the potential impact of these advancements on future space missions and exploration.</s>\n<|assistant|>\nIn recent years, space exploration has reached new heights with exciting discoveries and technological advancements that have changed our understanding of the universe. From the discovery of exoplanets to the development of more efficient spacecraft, the latest breakthroughs in space exploration are guiding us towards a new era of space science and exploration.\n\nOne recent discovery that has rocked the space science world is the discovery of the TRAPPIST-1 system, which contains seven Earth-sized planets, three of which are within the habitable zone of the star. This discovery has raised the possibility of there being an extraterrestrial life on planets beyond our solar system. NASA's Spitzer Space Telescope was instrumental in this discovery, as it allowed researchers to study the light emitted by the planets, enabling them to determine their size, distance from their star, and the likelihood of the planet having an atmosphere.\n\nOther advances in technology have also made a significant impact on space exploration. The development of ion propulsion systems has led to more efficient spacecraft, which can travel faster and farther than any spacecraft in the past. NASA's Dawn spacecraft was the first to use this technology, exploring two of the largest objects in the asteroid belt, Ceres and Vesta. The successful use of ion propulsion systems has opened the door to more ambitious missions to explore the deep space.\n\nAnother technological breakthrough that has significantly impacted space exploration is the development of 3D printing technology. One such use of this technology was seen in the International Space Station, where it was used to produce spare parts, tools, and equipment that were not possible to be produced in space earlier. This technology reduces the dependence on shipping parts from Earth and allows for a more sustainable space mission.\n\nThe latest advancements are not just back on Earth but on the flightpaths too. In April 2021, NASA's Ingenuity helicopter became the first aircraft ever to fly on another planet. This achievement could pave the way for future missions to explore the Martian terrain more efficiently, as aerial vehicles enable scientists to study the planet's surface from a new perspective.\n\nThe impact of these advancements is substantial and could change the course of space exploration. With the discovery of exoplanets, we may be closer to developing new life-support mechanisms and travel systems that cater to interstellar travel. Ion propulsion technology is a groundwork for future manned space missions to Mars or deep space, where travel time could be reasonably reduced, and using three-day parts when needed will help in surviving missions without depending on supplies from Earth, whilst 3D printing technology will have many benefits for space survival.\n\nIn conclusion, the advancements in space exploration are advancing rapidly. These breakthroughs are changing our understanding of our discoveries and technological measures, making it easier and efficient to explore beyond the horizon. With such breakthroughs, we may be closer to exploring the far reaches of space and discovering new frontiers like never before.</s>\n<|user|>\nWow, these advancements in space exploration are really fascinating! I'd love to know more about the ion propulsion systems and how they work. Could you add more information about that?</s>\n<|assistant|>\nCertainly! Ion propulsion systems are an alternative to traditional chemical rocket engines used in space travel. They work by expelling charged particles, known as ions, at high speeds out of the back of the spacecraft, producing thrust in the opposite direction.\n\nIon engines use electric fields to ionize a propellant, usually xenon or argon gas, which accelerates the ions up to speeds of around 90,000 mph. This is much faster than traditional chemical rockets, which typically only reach speeds of about 25,000 mph.\n\nThe electric fields are generated by an electric power source, usually solar panels, which supply electricity to the engine's components. The ions are then shot out the back of the engine, propelling the spacecraft forward.\n\nThe main advantage of ion propulsion systems is that they are much more efficient than traditional chemical rockets, allowing spacecraft to travel farther and faster using less fuel. This opens up new possibilities for exploring deep space and reaching destinations that were previously out of reach.\n\nOne downside to ion propulsion systems is that they produce relatively low levels of thrust, which means they cannot be used to launch spacecraft into space from Earth's surface. Instead, they are typically used to move spacecraft already in orbit, such as the Dawn spacecraft which traveled to the asteroids Vesta and Ceres.\n\nIon propulsion technology is expected to play a significant role in future human space exploration missions, enabling faster and more efficient travel to destinations such as Mars and beyond.</s>\n<|user|>\nThat sounds super interesting. Can you give me some examples of real-life spacecraft that use this technology?</s>\n<|assistant|>\nSure! Several spacecraft have used or are currently using ion propulsion technology. Here are a few examples:\n\n1. NASA's Dawn spacecraft: This spacecraft used ion thrusters to explore the asteroids Vesta and Ceres from 2007 to 2018. The ion engines allowed Dawn to travel to and orbit these asteroids for extended periods, taking high-resolution images and collecting data on their composition and structure. 2. NASA's Deep Space 1 (DS1) spacecraft: Launched in 1998, DS1 was the first spacecraft to use ion thrusters. The mission tested several advanced technologies, including the ion engines, which allowed the spacecraft to reach speeds of up to 24,000 mph (39,000 km/h). 3. The European Space Agency's (ESA) SMART-1 spacecraft: Launched in 2003, SMART-1 used ion engines to reach the moon, where it orbited and conducted scientific experiments for several months. 4. NASA's BepiColombo spacecraft: Launched in 2018, BepiColombo is on a mission to study the planet Mercury. The spacecraft uses ion engines to adjust its trajectory and reach Mercury, which has a strong gravitational pull. 5. NASA's Juno spacecraft: Launched in 2011, the Juno spacecraft used ion thrusters during its journey to Jupiter, which began in 2016. The ion engines allowed the spacecraft to travel faster and more efficiently than a traditional chemical rocket. These are just a few examples of the many spacecraft that have used or are currently using ion propulsion technology. As advancements in this technology continue, we can expect to see even more ambitious space missions using ion engines in the future.</s>\n<|user|>\nThis is all super cool! Can you tell me more about the SMART-1 spacecraft and what it discovered while orbiting the moon?</s>\n<|assistant|>\nYes, of course! The SMART-1 mission was launched by the European Space Agency (ESA) in 2003, with the primary goal of demonstrating the use of ion propulsion technology in deep space missions. After a series of spiraling orbits around the Earth, SMART-1 reached the moon in 2004.\n\nWhile in orbit, SMART-1 used a suite of scientific instruments to study the moon's surface and geology. One of its main instruments was a camera that allowed it to capture high-resolution images of the moon's surface. SMART-1 was able to detect the composition of the moon's surface and identify several previously unknown volcanic features.\n\nOne of the most significant discoveries made by SMART-1 was the detection of deposits of water ice on the moon's surface. The spacecraft's spectrometer detected the presence of hydrogen, which was likely stored in the form of water ice in permanently shadowed craters near the moon's poles. This discovery was important because it suggested that water could be a more common resource in the solar system than previously thought and might be used as a source of fuel or even for supporting human exploration on the moon in the future.\n\nSMART-1's mission ended in 2006 when the spacecraft was deliberately crashed into the moon's surface as part of a controlled impact. The impact was carefully monitored by ground-based telescopes and provided valuable data on the moon's geology and structure.\n\nOverall, SMART-1's mission was a milestone in the use of ion propulsion technology in space exploration and contributed significantly to our understanding of the moon.</s>\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BitsAndBytesConfig\nimport torch\n\n# specify how to quantize the model\nquantization_config = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_use_double_quant=True,\n            bnb_4bit_quant_type=\"nf4\",\n            bnb_4bit_compute_dtype=torch.bfloat16,\n)\ndevice_map = \"auto\"#{\"\": torch.cuda.current_device()} if torch.cuda.is_available() else None\n\nmodel_kwargs = dict(\n#     attn_implementation=False,#\"flash_attention_2\", # set this to True if your GPU supports it (Flash Attention drastically speeds up model computations)\n    torch_dtype=\"auto\",\n    use_cache=False, # set to False as we're going to use gradient checkpointing\n    device_map=device_map,\n    quantization_config=quantization_config,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T19:23:24.860446Z","iopub.execute_input":"2024-04-16T19:23:24.861099Z","iopub.status.idle":"2024-04-16T19:23:24.873100Z","shell.execute_reply.started":"2024-04-16T19:23:24.861066Z","shell.execute_reply":"2024-04-16T19:23:24.872157Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom peft import LoraConfig\nfrom transformers import TrainingArguments","metadata":{"execution":{"iopub.status.busy":"2024-04-16T19:23:24.874200Z","iopub.execute_input":"2024-04-16T19:23:24.874538Z","iopub.status.idle":"2024-04-16T19:23:33.050493Z","shell.execute_reply.started":"2024-04-16T19:23:24.874502Z","shell.execute_reply":"2024-04-16T19:23:33.049734Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"2024-04-16 19:23:28.851691: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-16 19:23:28.851763: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-16 19:23:28.863153: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install huggingface_hub","metadata":{"execution":{"iopub.status.busy":"2024-04-16T19:23:33.051614Z","iopub.execute_input":"2024-04-16T19:23:33.052209Z","iopub.status.idle":"2024-04-16T19:23:45.212273Z","shell.execute_reply.started":"2024-04-16T19:23:33.052178Z","shell.execute_reply":"2024-04-16T19:23:45.211152Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.22.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import interpreter_login\ninterpreter_login()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T19:23:45.213862Z","iopub.execute_input":"2024-04-16T19:23:45.214188Z","iopub.status.idle":"2024-04-16T19:24:24.986000Z","shell.execute_reply.started":"2024-04-16T19:23:45.214158Z","shell.execute_reply":"2024-04-16T19:24:24.985026Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"\n    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n\n    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n    Setting a new token will erase the existing one.\n    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your token (input will not be visible):  ·····································\nAdd token as git credential? (Y/n)  n\n"},{"name":"stdout","text":"Token is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"import gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T19:24:27.441863Z","iopub.execute_input":"2024-04-16T19:24:27.442245Z","iopub.status.idle":"2024-04-16T19:24:27.770157Z","shell.execute_reply.started":"2024-04-16T19:24:27.442214Z","shell.execute_reply":"2024-04-16T19:24:27.769197Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"23"},"metadata":{}}]},{"cell_type":"code","source":"# path where the Trainer will save its checkpoints and logs\noutput_dir = 'trained_models/Mistral-7b-sft-lora-ultrachat'\n\n# based on config\ntraining_args = TrainingArguments(\n    fp16=False, # specify bf16=True instead when training on GPUs that support bf16 else fp16\n    bf16=False,\n    do_eval=True,\n    evaluation_strategy=\"epoch\",\n    gradient_accumulation_steps=128,\n    gradient_checkpointing=True,\n    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n    learning_rate=2.0e-05,\n    log_level=\"info\",\n    logging_steps=5,\n    logging_strategy=\"steps\",\n    lr_scheduler_type=\"cosine\",\n    max_steps=-1,\n    num_train_epochs=1,\n    output_dir=output_dir,\n    overwrite_output_dir=True,\n    per_device_eval_batch_size=1, # originally set to 8\n    per_device_train_batch_size=1, # originally set to 8\n    push_to_hub=True,\n    hub_model_id=\"Mistral-7b-sft-lora-ultrachat\",\n    # hub_strategy=\"every_save\",\n    # report_to=\"tensorboard\",\n    save_strategy=\"no\",\n    save_total_limit=None,\n    seed=42,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T19:24:32.450253Z","iopub.execute_input":"2024-04-16T19:24:32.451201Z","iopub.status.idle":"2024-04-16T19:24:32.463636Z","shell.execute_reply.started":"2024-04-16T19:24:32.451158Z","shell.execute_reply":"2024-04-16T19:24:32.462681Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# based on config\npeft_config = LoraConfig(\n        r=64,\n        lora_alpha=16,\n        lora_dropout=0.1,\n        bias=\"none\",\n        task_type=\"CAUSAL_LM\",\n        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T19:24:37.348366Z","iopub.execute_input":"2024-04-16T19:24:37.349230Z","iopub.status.idle":"2024-04-16T19:24:37.354105Z","shell.execute_reply.started":"2024-04-16T19:24:37.349197Z","shell.execute_reply":"2024-04-16T19:24:37.352973Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"trainer = SFTTrainer(\n        model=model_id,\n        model_init_kwargs=model_kwargs,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=eval_dataset,\n        dataset_text_field=\"text\",\n        tokenizer=tokenizer,\n        packing=True,\n        peft_config=peft_config,\n        max_seq_length=tokenizer.model_max_length,\n    )","metadata":{"execution":{"iopub.status.busy":"2024-04-16T19:24:38.151638Z","iopub.execute_input":"2024-04-16T19:24:38.151989Z","iopub.status.idle":"2024-04-16T19:24:50.394510Z","shell.execute_reply.started":"2024-04-16T19:24:38.151963Z","shell.execute_reply":"2024-04-16T19:24:50.393659Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:166: UserWarning: You passed a model_id to the SFTTrainer. This will automatically create an `AutoModelForCausalLM` or a `PeftModel` (if you passed a `peft_config`) for you.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30e2a8c1c3e34bab9e94834ecee8fa68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90c0ff5c2c194491a22f52d568d8f0e9"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (2479 > 2048). Running this sequence through the model will result in indexing errors\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\nYou have loaded a model on multiple GPUs. `is_model_parallel` attribute will be force-set to `True` to avoid any unexpected behavior such as device placement mismatching.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_result = trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T19:25:15.617428Z","iopub.execute_input":"2024-04-16T19:25:15.618146Z","iopub.status.idle":"2024-04-16T20:02:46.835778Z","shell.execute_reply.started":"2024-04-16T19:25:15.618107Z","shell.execute_reply":"2024-04-16T20:02:46.834901Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"***** Running training *****\n  Num examples = 67\n  Num Epochs = 1\n  Instantaneous batch size per device = 1\n  Total train batch size (w. parallel, distributed & accumulation) = 128\n  Gradient Accumulation steps = 128\n  Total optimization steps = 1\n  Number of trainable parameters = 54,525,952\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mavishek-paul\u001b[0m (\u001b[33mds_montreal\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240416_192517-v3am6f6z</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ds_montreal/huggingface/runs/v3am6f6z/workspace' target=\"_blank\">glowing-hill-18</a></strong> to <a href='https://wandb.ai/ds_montreal/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ds_montreal/huggingface' target=\"_blank\">https://wandb.ai/ds_montreal/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ds_montreal/huggingface/runs/v3am6f6z/workspace' target=\"_blank\">https://wandb.ai/ds_montreal/huggingface/runs/v3am6f6z/workspace</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 09:05, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.380752</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 64\n  Batch size = 1\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"train_result","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:04:37.787049Z","iopub.execute_input":"2024-04-16T20:04:37.787420Z","iopub.status.idle":"2024-04-16T20:04:37.795048Z","shell.execute_reply.started":"2024-04-16T20:04:37.787392Z","shell.execute_reply":"2024-04-16T20:04:37.793957Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1, training_loss=0.7032263875007629, metrics={'train_runtime': 2250.8542, 'train_samples_per_second': 0.03, 'train_steps_per_second': 0.0, 'total_flos': 5899069012574208.0, 'train_loss': 0.7032263875007629, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"dir(trainer)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:05:13.507156Z","iopub.execute_input":"2024-04-16T20:05:13.507548Z","iopub.status.idle":"2024-04-16T20:05:13.518940Z","shell.execute_reply.started":"2024-04-16T20:05:13.507517Z","shell.execute_reply":"2024-04-16T20:05:13.518004Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"['__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_activate_neftune',\n '_add_sm_patterns_to_gitignore',\n '_created_lr_scheduler',\n '_deactivate_neftune',\n '_finish_current_push',\n '_fsdp_qlora_plugin_updates',\n '_gather_and_numpify',\n '_get_collator_with_removed_columns',\n '_get_eval_sampler',\n '_get_learning_rate',\n '_get_output_dir',\n '_get_train_sampler',\n '_globalstep_last_logged',\n '_hp_search_setup',\n '_inner_training_loop',\n '_issue_warnings_after_load',\n '_load_best_model',\n '_load_from_checkpoint',\n '_load_optimizer_and_scheduler',\n '_load_rng_state',\n '_loggers_initialized',\n '_maybe_log_save_evaluate',\n '_memory_tracker',\n '_move_model_to_device',\n '_nested_gather',\n '_prepare_dataset',\n '_prepare_input',\n '_prepare_inputs',\n '_prepare_non_packed_dataloader',\n '_prepare_packed_dataloader',\n '_push_from_checkpoint',\n '_remove_unused_columns',\n '_report_to_hp_search',\n '_rotate_checkpoints',\n '_save',\n '_save_checkpoint',\n '_save_optimizer_and_scheduler',\n '_save_rng_state',\n '_save_tpu',\n '_set_signature_columns_if_needed',\n '_signature_columns',\n '_sorted_checkpoints',\n '_tag_names',\n '_total_loss_scalar',\n '_train_batch_size',\n '_trainer_supports_neftune',\n '_trial',\n '_trl_activate_neftune',\n '_tune_save_checkpoint',\n '_wrap_model',\n 'accelerator',\n 'add_callback',\n 'args',\n 'autocast_smart_context_manager',\n 'call_model_init',\n 'callback_handler',\n 'can_return_loss',\n 'compute_loss',\n 'compute_loss_context_manager',\n 'compute_metrics',\n 'control',\n 'create_accelerator_and_postprocess',\n 'create_model_card',\n 'create_optimizer',\n 'create_optimizer_and_scheduler',\n 'create_scheduler',\n 'current_flos',\n 'data_collator',\n 'dataset_batch_size',\n 'dataset_num_proc',\n 'deepspeed',\n 'eval_dataset',\n 'evaluate',\n 'evaluation_loop',\n 'floating_point_ops',\n 'gather_function',\n 'get_decay_parameter_names',\n 'get_eval_dataloader',\n 'get_optimizer_cls_and_kwargs',\n 'get_test_dataloader',\n 'get_train_dataloader',\n 'hp_name',\n 'hp_search_backend',\n 'hub_model_id',\n 'hyperparameter_search',\n 'init_hf_repo',\n 'ipex_optimize_model',\n 'is_deepspeed_enabled',\n 'is_fsdp_enabled',\n 'is_fsdp_xla_enabled',\n 'is_fsdp_xla_v2_enabled',\n 'is_in_train',\n 'is_local_process_zero',\n 'is_model_parallel',\n 'is_world_process_zero',\n 'label_names',\n 'label_smoother',\n 'log',\n 'log_metrics',\n 'lr_scheduler',\n 'metrics_format',\n 'model',\n 'model_init',\n 'model_wrapped',\n 'neftune_noise_alpha',\n 'num_examples',\n 'num_tokens',\n 'optimizer',\n 'place_model_on_device',\n 'pop_callback',\n 'predict',\n 'prediction_loop',\n 'prediction_step',\n 'preprocess_logits_for_metrics',\n 'propagate_args_to_deepspeed',\n 'push_in_progress',\n 'push_to_hub',\n 'remove_callback',\n 'save_metrics',\n 'save_model',\n 'save_state',\n 'state',\n 'store_flos',\n 'tokenizer',\n 'torch_jit_model_eval',\n 'train',\n 'train_dataset',\n 'training_step',\n 'use_apex',\n 'use_cpu_amp']"},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub(\"Mistral-7b-sft-lora-ultrachat\")","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:06:42.616420Z","iopub.execute_input":"2024-04-16T20:06:42.616829Z","iopub.status.idle":"2024-04-16T20:06:52.255009Z","shell.execute_reply.started":"2024-04-16T20:06:42.616798Z","shell.execute_reply":"2024-04-16T20:06:52.253879Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Saving model checkpoint to trained_models/Mistral-7b-sft-lora-ultrachat\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.2/snapshots/41b61a33a2483885c981aa79e0df6b32407ed873/config.json\nModel config MistralConfig {\n  \"architectures\": [\n    \"MistralForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 14336,\n  \"max_position_embeddings\": 32768,\n  \"model_type\": \"mistral\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 8,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.39.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 32000\n}\n\ntokenizer config file saved in trained_models/Mistral-7b-sft-lora-ultrachat/tokenizer_config.json\nSpecial tokens file saved in trained_models/Mistral-7b-sft-lora-ultrachat/special_tokens_map.json\nDropping the following result as it does not have all the necessary fields:\n{'dataset': {'name': 'generator', 'type': 'generator', 'config': 'default', 'split': 'train', 'args': 'default'}}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66d513693d0a45659f879f00c40d6668"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1713294955.e8dd955df3fb.34.0:   0%|          | 0.00/5.23k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a757e09320e4488bb3a310f8e08f793"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/218M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e084f9f9924473299a6d2baff5a3184"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1713295515.e8dd955df3fb.361.0:   0%|          | 0.00/5.84k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fd0b72fa61a4d1ba33a96ddd2472d70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba61e218ed514007b518b0713e43bf9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 5 LFS files:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05635d8782704a7eb4b4cdb394fedf00"}},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/APaul1/Mistral-7b-sft-lora-ultrachat/commit/b55a2c6dbd557a0c5276e53d77ded48ba774bb05', commit_message='Mistral-7b-sft-lora-ultrachat', commit_description='', oid='b55a2c6dbd557a0c5276e53d77ded48ba774bb05', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"metrics = train_result.metrics\nmax_train_samples = 1000#training_args.max_train_samples if training_args.max_train_samples is not None else len(train_dataset)\nmetrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\ntrainer.log_metrics(\"train\", metrics)\ntrainer.save_metrics(\"train\", metrics)\ntrainer.save_state()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:09:18.956902Z","iopub.execute_input":"2024-04-16T20:09:18.958203Z","iopub.status.idle":"2024-04-16T20:09:18.968686Z","shell.execute_reply.started":"2024-04-16T20:09:18.958164Z","shell.execute_reply":"2024-04-16T20:09:18.967771Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"***** train metrics *****\n  epoch                    =        1.0\n  total_flos               =  5493936GF\n  train_loss               =     0.7032\n  train_runtime            = 0:37:30.85\n  train_samples            =        100\n  train_samples_per_second =       0.03\n  train_steps_per_second   =        0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}